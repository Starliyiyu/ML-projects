{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, \\\n",
    "    Dropout, BatchNormalization\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Dataset 1\n",
    "\n",
    "with open('financial_phrasebank/Sentences_75Agree.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize empty lists for text and sentiment\n",
    "texts = []\n",
    "sentiments = []\n",
    "\n",
    "# Iterate over each line in the file\n",
    "for line in lines:\n",
    "    # Split the line at the '@' symbol\n",
    "    parts = line.strip().split('@')\n",
    "    if len(parts) == 2:\n",
    "        # Extract the text and sentiment\n",
    "        text = parts[0].strip()\n",
    "        sentiment = parts[1].strip()\n",
    "\n",
    "        # Append the text and sentiment to the respective lists\n",
    "        texts.append(text)\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "# Create a dataframe from the extracted data\n",
    "ds_one = pd.DataFrame({'text': texts, 'sentiment': sentiments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     2146\n",
      "positive     887\n",
      "negative     420\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# EDA\n",
    "\n",
    "# sentiment distribution\n",
    "print(ds_one['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Star\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Star\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Star\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text data\n",
    "\n",
    "# use stopwords and wordnet collections in the nltk package\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "# use pre-trained model for initial tokenization\n",
    "# i.e. the sentence will split at what punctuations\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Tokenize the lowercased text into individual words\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords: common words like \"a,\" \"an,\" \"the,\" \"and,\" etc.\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Remove punctuations \n",
    "    words = [word for word in words if word not in string.punctuation]\n",
    "\n",
    "    # Lemmatize words: reduces words to their base or dictionary form\n",
    "    # i.e. \"running\" to \"run\"\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join words back into a sentence\n",
    "    preprocessed_text = ' '.join(words)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "ds_one['text'] = ds_one['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds_one['text'].values\n",
    "y = ds_one['sentiment'].values\n",
    "\n",
    "# encode the sentiment labels to numeric format\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# uncomment the following code to get the encoding mapping\n",
    "# negative: 0\n",
    "# neutral: 1\n",
    "# positive: 2\n",
    "\n",
    "# class_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "# for class_label, encoded_value in class_mapping.items():\n",
    "#     print(f\"{class_label}: {encoded_value}\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# note that we preserve the sentiment distribution\n",
    "# to handle the sentiment imbalance\n",
    "\n",
    "# val -> validation\n",
    "X_train_val, X_test, y_train_val, y_test = \\\n",
    "train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "# preserve the sentiment distribution\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X_train_val, y_train_val, test_size=0.2,\n",
    "                      random_state=42, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second tokenization and pad the sequences\n",
    "\n",
    "# we switch to the numerical tokenizer from tensorflow package\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# builds the vocabulary and assigns a unique index to each word in the text\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# convert the text data into sequences of numerical tokens\n",
    "# based on the vocabulary learned by the tokenizer\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# the total number of unique tokens in the vocabulary\n",
    "# later used in the embedding layer of the model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "\n",
    "# LSTM models require input sequences to have the same length\n",
    "# To address this, we pad the sequences to a maximum length as follows:\n",
    "# Sequences longer than max_len are truncated, \n",
    "# and shorter sequences are padded with zeros at the beginning\n",
    "\n",
    "# *5 because the announcement paragraphs are usually 4-5 sentences\n",
    "# per paragraph\n",
    "max_len = max([len(x)*5 for x in X_train])\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_val = pad_sequences(X_val, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save y_train before one-hot coding for optimization trial 4\n",
    "y_train_opt = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 7s 132ms/step - loss: 1.0524 - accuracy: 0.6016 - val_loss: 0.9390 - val_accuracy: 0.6221\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 0.8770 - accuracy: 0.6215 - val_loss: 0.8275 - val_accuracy: 0.6221\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 0.7841 - accuracy: 0.6329 - val_loss: 0.7448 - val_accuracy: 0.6673\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.6762 - accuracy: 0.6904 - val_loss: 0.6821 - val_accuracy: 0.7052\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.5651 - accuracy: 0.7329 - val_loss: 0.6352 - val_accuracy: 0.7197\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.4625 - accuracy: 0.7918 - val_loss: 0.6403 - val_accuracy: 0.7505\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 87ms/step - loss: 0.4050 - accuracy: 0.8447 - val_loss: 0.6294 - val_accuracy: 0.7523\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.3412 - accuracy: 0.8443 - val_loss: 0.6248 - val_accuracy: 0.7523\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 86ms/step - loss: 0.2874 - accuracy: 0.8705 - val_loss: 0.6454 - val_accuracy: 0.7631\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 86ms/step - loss: 0.2376 - accuracy: 0.8950 - val_loss: 0.6605 - val_accuracy: 0.7523\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 85ms/step - loss: 0.1898 - accuracy: 0.9303 - val_loss: 0.6448 - val_accuracy: 0.7414\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 85ms/step - loss: 0.1529 - accuracy: 0.9593 - val_loss: 0.6756 - val_accuracy: 0.7685\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.1157 - accuracy: 0.9778 - val_loss: 0.7291 - val_accuracy: 0.7794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe62991cd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 3  # Number of sentiment categories (positive, negative, neutral)\n",
    "\n",
    "# Convert class labels to one-hot encoding:\n",
    "\n",
    "# converts the categorical labels into a binary matrix representation\n",
    "# where each class label is represented by a row vector with a value of 1\n",
    "# in the corresponding class index and 0 elsewhere.\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "# build the LSTM model\n",
    "\n",
    "# model structure: \n",
    "\n",
    "# sequential model\n",
    "model = Sequential()\n",
    "# embedding layer\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=max_len))\n",
    "# LSTM layer\n",
    "model.add(LSTM(units=32))\n",
    "# dense layer for classification\n",
    "\n",
    "# choice of activation function: softmax\n",
    "# common choice for multi-class classification\n",
    "# it outputs a probability distribution across the sentiments (pos/neg/neutral), \n",
    "# ensuring that the predicted probabilities sum up to 1.\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Specify the loss function, optimizer, and evaluation metrics\n",
    "\n",
    "# choice of loss: categorical_crossentropy\n",
    "# common choice for multi-class classification\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# train the model\n",
    "# epochs and batch size can be tuned later on\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "          epochs=30, batch_size=128, callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6097 - accuracy: 0.7583\n",
      "Test Loss: 0.6097\n",
      "Test Accuracy: 0.7583\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Dataset 2A (small sample manually reviewed and collected)\n",
    "paragraph_reviewed = pd.read_csv('sentiment_by_paragraphs.csv')\n",
    "article_reviewed = pd.read_csv('overall_sentiment_by_article.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of paragraphs in total: 127\n",
      "neutral     52\n",
      "positive    48\n",
      "negative    27\n",
      "Name: sentiment, dtype: int64\n",
      "   aID                                       text_content sentiment\n",
      "0    1  The Bank of Canada and the Bank of Korea today...  positive\n",
      "1    2  MONTRÉAL, QUEBEC—The fundamental forces that h...   neutral\n",
      "2    2  In a speech to CFA Montréal and the Montreal C...  positive\n",
      "3    2  Inflation has underperformed forecasts mostly ...   neutral\n",
      "4    2  The fundamental drivers of inflation, along wi...   neutral\n"
     ]
    }
   ],
   "source": [
    "# EDA & data cleaning for Dataset 2A\n",
    "\n",
    "# number of paragraphs\n",
    "print(\"number of paragraphs in total:\", paragraph_reviewed.shape[0])\n",
    "\n",
    "# sentiment distribution\n",
    "print(paragraph_reviewed['sentiment'].value_counts())\n",
    "\n",
    "# print(paragraph_reviewed.head())\n",
    "# found invalid columns\n",
    "\n",
    "# drop invalid columns\n",
    "paragraph_reviewed = paragraph_reviewed.drop(\n",
    "    columns=['Unnamed: 3', 'Unnamed: 4'])\n",
    "\n",
    "# cleaned datasets\n",
    "print(paragraph_reviewed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 19ms/step - loss: 1.6110 - accuracy: 0.4173\n",
      "Test Loss: 1.6110\n",
      "Test Accuracy: 0.4173\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the paragraphs\n",
    "\n",
    "# same procedure as preprocessing Dataset 1\n",
    "\n",
    "paragraph_reviewed['text_content'] = paragraph_reviewed[\n",
    "    'text_content'].apply(preprocess_text)\n",
    "\n",
    "paragraph_reviewed_X = paragraph_reviewed['text_content'].values\n",
    "paragraph_reviewed_y = paragraph_reviewed['sentiment'].values\n",
    "\n",
    "# tokenize and pad the sequences\n",
    "paragraph_reviewed_X = tokenizer.texts_to_sequences(paragraph_reviewed_X)\n",
    "paragraph_reviewed_X = pad_sequences(paragraph_reviewed_X, maxlen=max_len)\n",
    "\n",
    "# convert to numeric category & one-hot code y\n",
    "paragraph_reviewed_y = le.fit_transform(paragraph_reviewed_y)\n",
    "paragraph_reviewed_y = to_categorical(paragraph_reviewed_y, num_classes)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(paragraph_reviewed_X, paragraph_reviewed_y)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 17 10]\n",
      " [ 0 36 16]\n",
      " [ 0 31 17]]\n"
     ]
    }
   ],
   "source": [
    "# only 40% accuracy, could be attributed to the different distribution of \n",
    "# sentiments in Dataset 2A than in Dataset 1\n",
    "\n",
    "# let's look at the confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "predictions = model.predict(paragraph_reviewed_X)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(np.argmax(paragraph_reviewed_y, \n",
    "                                                      axis=1), \n",
    "                                            predicted_labels)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative: 0\n",
      "neutral: 84\n",
      "positive: 43\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each class label\n",
    "label_counts = np.bincount(predicted_labels)\n",
    "\n",
    "# Get the class names\n",
    "class_names = ['negative', 'neutral', 'positive']\n",
    "\n",
    "# Create a dictionary to store the distribution\n",
    "distribution = dict(zip(class_names, label_counts))\n",
    "\n",
    "# Print the distribution\n",
    "for label, count in distribution.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the confusion matrix:\n",
    "# None of the negative paragraphs are correctly classified\n",
    "# too many paragraphs are classified as neutral \n",
    "# less than half of the positive paragraphs are correctly classified\n",
    "\n",
    "# a likely reason is the distribution of sentiment in the training dataset (Dataset 1)\n",
    "# in which:\n",
    "# 62% sentences are neutral\n",
    "# 12% sentences are negative\n",
    "# 26% sentences are positive\n",
    "\n",
    "# possible ways to reduce the distribution bias:\n",
    "\n",
    "# - regularize, ex. dropout\n",
    "\n",
    "# - custom loss functions that penalize incorrect predictions on the minority classes more heavily\n",
    "\n",
    "# - assign different weights to each class during the model training\n",
    "\n",
    "# - undersampling / oversampling by randomly duplicating minority samples\n",
    "\n",
    "# - Ensemble Models: Train multiple LSTM models using different subsets of the data, then aggregate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 4s 126ms/step - loss: 1.0803 - accuracy: 0.5989 - val_loss: 1.0493 - val_accuracy: 0.6221\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.9904 - accuracy: 0.6215 - val_loss: 0.8943 - val_accuracy: 0.6221\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.8795 - accuracy: 0.6215 - val_loss: 0.8490 - val_accuracy: 0.6221\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.8213 - accuracy: 0.6215 - val_loss: 0.7919 - val_accuracy: 0.6383\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.7571 - accuracy: 0.6573 - val_loss: 0.7360 - val_accuracy: 0.6908\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 0.6776 - accuracy: 0.6922 - val_loss: 0.6880 - val_accuracy: 0.7161\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 0.6026 - accuracy: 0.7230 - val_loss: 0.6553 - val_accuracy: 0.7197\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 0.5292 - accuracy: 0.7592 - val_loss: 0.6329 - val_accuracy: 0.7251\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.4719 - accuracy: 0.7913 - val_loss: 0.6428 - val_accuracy: 0.7342\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 0.4316 - accuracy: 0.8072 - val_loss: 0.6499 - val_accuracy: 0.7486\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.3944 - accuracy: 0.8307 - val_loss: 0.6228 - val_accuracy: 0.7559\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.3624 - accuracy: 0.8447 - val_loss: 0.6503 - val_accuracy: 0.7649\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 0.3363 - accuracy: 0.8506 - val_loss: 0.6358 - val_accuracy: 0.7577\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.4787 - accuracy: 0.8388 - val_loss: 0.6438 - val_accuracy: 0.7269\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 0.3611 - accuracy: 0.8542 - val_loss: 0.6631 - val_accuracy: 0.7505\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.3287 - accuracy: 0.8533 - val_loss: 0.6527 - val_accuracy: 0.7468\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6284 - accuracy: 0.7641\n",
      "Test Loss: 0.6284\n",
      "Test Accuracy: 0.7641\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4485 - accuracy: 0.4016\n",
      "Announcement data test Loss: 1.4485\n",
      "Announcement data test Accuracy: 0.4016\n"
     ]
    }
   ],
   "source": [
    "# optimize the model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# trial 1 (discarded): regularize by adding dropout\n",
    "# and apply a smaller learning rate to the optimizer\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=max_len))\n",
    "# dropput: 20% of the LSTM layer's input units are randomly set to 0\n",
    "model_1.add(LSTM(units=32, dropout=0.2)) \n",
    "\n",
    "model_1.add(Dense(units=num_classes, activation='softmax'))\n",
    "# adam optimizer with a slower learning rate (default is 0.001)\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "          epochs=30, batch_size=128, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model_1.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the bank announcement data\n",
    "loss, accuracy = model_1.evaluate(paragraph_reviewed_X, paragraph_reviewed_y)\n",
    "\n",
    "print(f\"Announcement data test Loss: {loss:.4f}\")\n",
    "print(f\"Announcement data test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# result: some improvement on the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 17ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 15 12]\n",
      " [ 0 32 20]\n",
      " [ 0 29 19]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix under trial 1(discarded)\n",
    "\n",
    "predictions_1 = model_1.predict(paragraph_reviewed_X)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "predicted_labels_1 = np.argmax(predictions_1, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(np.argmax(paragraph_reviewed_y, \n",
    "                                                      axis=1), \n",
    "                                            predicted_labels_1)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 5s 124ms/step - loss: 1.0482 - accuracy: 0.4586 - val_loss: 1.0705 - val_accuracy: 0.6365\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 0.8777 - accuracy: 0.6546 - val_loss: 1.0449 - val_accuracy: 0.6510\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.6910 - accuracy: 0.7936 - val_loss: 1.0223 - val_accuracy: 0.6872\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.4878 - accuracy: 0.8551 - val_loss: 0.9866 - val_accuracy: 0.7269\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.3353 - accuracy: 0.8981 - val_loss: 0.9727 - val_accuracy: 0.7052\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.2172 - accuracy: 0.9393 - val_loss: 1.0578 - val_accuracy: 0.3273\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.1483 - accuracy: 0.9642 - val_loss: 1.1377 - val_accuracy: 0.1338\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.0956 - accuracy: 0.9814 - val_loss: 1.0493 - val_accuracy: 0.2893\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.0712 - accuracy: 0.9882 - val_loss: 1.3127 - val_accuracy: 0.1284\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.0546 - accuracy: 0.9959 - val_loss: 1.3389 - val_accuracy: 0.2875\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.9727 - accuracy: 0.7135\n",
      "Test Loss: 0.9727\n",
      "Test Accuracy: 0.7135\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1215 - accuracy: 0.3701\n",
      "Announcement data test Loss: 1.1215\n",
      "Announcement data test Accuracy: 0.3701\n"
     ]
    }
   ],
   "source": [
    "# trial 2(discarded): regularize by adding batch normalization\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=max_len))\n",
    "model_2.add(LSTM(units=32)) \n",
    "# batch normalization layer added\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dense(units=num_classes, activation='softmax'))\n",
    "# keep the adam optimizer with a slower learning rate from trial 1\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "          epochs=30, batch_size=128, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model_2.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the bank announcement data\n",
    "loss, accuracy = model_2.evaluate(paragraph_reviewed_X, paragraph_reviewed_y)\n",
    "\n",
    "print(f\"Announcement data test Loss: {loss:.4f}\")\n",
    "print(f\"Announcement data test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# result: bad accuracy, do not include in ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 19ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4 18  5]\n",
      " [13 28 11]\n",
      " [ 8 25 15]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix under trial 2(discarded)\n",
    "\n",
    "predictions_2 = model_2.predict(paragraph_reviewed_X)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "predicted_labels_2 = np.argmax(predictions_2, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(np.argmax(paragraph_reviewed_y, \n",
    "                                                      axis=1), \n",
    "                                            predicted_labels_2)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 4s 118ms/step - loss: 0.4565 - accuracy: 0.4500 - val_loss: 0.4498 - val_accuracy: 0.6890\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.4402 - accuracy: 0.6691 - val_loss: 0.4225 - val_accuracy: 0.6347\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.3972 - accuracy: 0.6243 - val_loss: 0.3850 - val_accuracy: 0.6221\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.3773 - accuracy: 0.6704 - val_loss: 0.3700 - val_accuracy: 0.7016\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.3539 - accuracy: 0.6999 - val_loss: 0.3430 - val_accuracy: 0.7143\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.3123 - accuracy: 0.7420 - val_loss: 0.3127 - val_accuracy: 0.7161\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.2637 - accuracy: 0.7700 - val_loss: 0.2865 - val_accuracy: 0.7306\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.2179 - accuracy: 0.7995 - val_loss: 0.2788 - val_accuracy: 0.7414\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.1896 - accuracy: 0.8271 - val_loss: 0.2720 - val_accuracy: 0.7414\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 0.1710 - accuracy: 0.8379 - val_loss: 0.2759 - val_accuracy: 0.7577\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.1514 - accuracy: 0.8470 - val_loss: 0.2804 - val_accuracy: 0.7613\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.1375 - accuracy: 0.8583 - val_loss: 0.2799 - val_accuracy: 0.7577\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.1250 - accuracy: 0.8597 - val_loss: 0.2780 - val_accuracy: 0.7559\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.1212 - accuracy: 0.8592 - val_loss: 0.2648 - val_accuracy: 0.7505\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.1100 - accuracy: 0.8674 - val_loss: 0.2714 - val_accuracy: 0.7468\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 0.1005 - accuracy: 0.8714 - val_loss: 0.2664 - val_accuracy: 0.7505\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.0931 - accuracy: 0.8769 - val_loss: 0.2797 - val_accuracy: 0.7667\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.0846 - accuracy: 0.8891 - val_loss: 0.2798 - val_accuracy: 0.7685\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.0785 - accuracy: 0.9009 - val_loss: 0.2700 - val_accuracy: 0.7559\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.2558 - accuracy: 0.7569\n",
      "Test Loss: 0.2558\n",
      "Test Accuracy: 0.7569\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6583 - accuracy: 0.3780\n",
      "Announcement data test Loss: 0.6583\n",
      "Announcement data test Accuracy: 0.3780\n"
     ]
    }
   ],
   "source": [
    "# trial 3 (now trial 1). use custom loss functions that penalize incorrect predictions\n",
    "# on the minority classes (i.e. 'negative') more heavily\n",
    "\n",
    "\n",
    "# define the custom loss function\n",
    "def penalized_loss(y_true, y_pred):\n",
    "    # Define weights for each class, higher weight for 'negative' class\n",
    "    class_weights = tf.constant([1.0, 1.0, 2.0]) \n",
    "\n",
    "    # Apply weights to the loss calculation\n",
    "    weighted_loss = tf.multiply(y_true * tf.math.log(y_pred), class_weights)\n",
    "    loss = -tf.reduce_mean(weighted_loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=max_len))\n",
    "model_3.add(LSTM(units=32)) \n",
    "model_3.add(Dense(units=num_classes, activation='softmax'))\n",
    "# adam optimizer with a slower learning rate (default is 0.001)\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model_3.compile(loss=penalized_loss, optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_3.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "          epochs=30, batch_size=128, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model_3.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the bank announcement data\n",
    "loss, accuracy = model_3.evaluate(paragraph_reviewed_X, paragraph_reviewed_y)\n",
    "\n",
    "print(f\"Announcement data test Loss: {loss:.4f}\")\n",
    "print(f\"Announcement data test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# result: performance similar to trial 1 (discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 19ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 15 12]\n",
      " [ 0 24 28]\n",
      " [ 0 24 24]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix under trial 3 (now trial 1)\n",
    "\n",
    "predictions_3 = model_3.predict(paragraph_reviewed_X)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "predicted_labels_3 = np.argmax(predictions_3, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(np.argmax(paragraph_reviewed_y, \n",
    "                                                      axis=1), \n",
    "                                            predicted_labels_3)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 4s 129ms/step - loss: 1.0962 - accuracy: 0.4676 - val_loss: 1.0773 - val_accuracy: 0.6401\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 1.0786 - accuracy: 0.6713 - val_loss: 1.0099 - val_accuracy: 0.6709\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 1.0382 - accuracy: 0.6781 - val_loss: 0.9383 - val_accuracy: 0.6727\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 0.9674 - accuracy: 0.6876 - val_loss: 0.8933 - val_accuracy: 0.6564\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 0.8769 - accuracy: 0.6858 - val_loss: 0.8255 - val_accuracy: 0.6546\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 101ms/step - loss: 0.7817 - accuracy: 0.7076 - val_loss: 0.7278 - val_accuracy: 0.6709\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.6950 - accuracy: 0.7438 - val_loss: 0.6694 - val_accuracy: 0.6908\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.6653 - accuracy: 0.7664 - val_loss: 0.7087 - val_accuracy: 0.6781\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 103ms/step - loss: 0.5867 - accuracy: 0.8121 - val_loss: 0.7153 - val_accuracy: 0.6835\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.5200 - accuracy: 0.8646 - val_loss: 0.6194 - val_accuracy: 0.7306\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 0.4688 - accuracy: 0.8873 - val_loss: 0.6198 - val_accuracy: 0.7360\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.4058 - accuracy: 0.9031 - val_loss: 0.6194 - val_accuracy: 0.7486\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 98ms/step - loss: 0.3522 - accuracy: 0.9244 - val_loss: 0.6217 - val_accuracy: 0.7468\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 99ms/step - loss: 0.2972 - accuracy: 0.9407 - val_loss: 0.6459 - val_accuracy: 0.7523\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.2541 - accuracy: 0.9407 - val_loss: 0.6461 - val_accuracy: 0.7468\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.6417 - accuracy: 0.7395\n",
      "Test Loss: 0.6417\n",
      "Test Accuracy: 0.7395\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.4212 - accuracy: 0.3307\n",
      "Announcement data test Loss: 1.4212\n",
      "Announcement data test Accuracy: 0.3307\n"
     ]
    }
   ],
   "source": [
    "# trial 4 (now trial 2): utilize class weighting during model training\n",
    "\n",
    "# computes the class weights based on the 'balanced' strategy\n",
    "# this strategy assigns weights inversely proportional to the class frequencies\n",
    "# i.e. 'negative' has very low frequency -> receive higher weights\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight = 'balanced', \n",
    "    classes = np.unique(np.argmax(y_train, axis=1)), \n",
    "    y = np.argmax(y_train, axis=1)\n",
    "    )\n",
    "\n",
    "# Convert class weights to dictionary format\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=max_len))\n",
    "model_4.add(LSTM(units=32)) \n",
    "model_4.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model_4.compile(loss='categorical_crossentropy', optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# add class weight param\n",
    "model_4.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "          epochs=30, batch_size=128, callbacks=[early_stopping],\n",
    "          class_weight=class_weights_dict)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model_4.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the bank announcement data\n",
    "loss, accuracy = model_4.evaluate(paragraph_reviewed_X, paragraph_reviewed_y)\n",
    "\n",
    "print(f\"Announcement data test Loss: {loss:.4f}\")\n",
    "print(f\"Announcement data test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# result: performance similar to trial 1 (discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 18ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2 16  9]\n",
      " [ 5 31 16]\n",
      " [ 3 36  9]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix under trial 4 (now trial 2)\n",
    "\n",
    "predictions_4 = model_4.predict(paragraph_reviewed_X)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "predicted_labels_4 = np.argmax(predictions_4, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(np.argmax(paragraph_reviewed_y, \n",
    "                                                      axis=1), \n",
    "                                            predicted_labels_4)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 4s 141ms/step - loss: 1.0967 - accuracy: 0.4203 - val_loss: 1.0914 - val_accuracy: 0.5805\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 1.0858 - accuracy: 0.5720 - val_loss: 1.0721 - val_accuracy: 0.6600\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.0649 - accuracy: 0.5767 - val_loss: 1.0153 - val_accuracy: 0.6727\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 1.0175 - accuracy: 0.5232 - val_loss: 0.9127 - val_accuracy: 0.6980\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.9390 - accuracy: 0.5914 - val_loss: 0.8390 - val_accuracy: 0.6546\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.8330 - accuracy: 0.6267 - val_loss: 0.8841 - val_accuracy: 0.6112\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.7189 - accuracy: 0.6943 - val_loss: 0.8850 - val_accuracy: 0.6184\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.6359 - accuracy: 0.7390 - val_loss: 0.7061 - val_accuracy: 0.6727\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.5668 - accuracy: 0.7566 - val_loss: 1.1703 - val_accuracy: 0.4756\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.5430 - accuracy: 0.7801 - val_loss: 0.7661 - val_accuracy: 0.6438\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.5030 - accuracy: 0.8189 - val_loss: 0.7346 - val_accuracy: 0.6637\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4615 - accuracy: 0.8301 - val_loss: 0.7495 - val_accuracy: 0.6637\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.4182 - accuracy: 0.8501 - val_loss: 0.8579 - val_accuracy: 0.6438\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.7110 - accuracy: 0.6918\n",
      "Test Loss: 0.7110\n",
      "Test Accuracy: 0.6918\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3747 - accuracy: 0.2126\n",
      "Announcement data test Loss: 1.3747\n",
      "Announcement data test Accuracy: 0.2126\n"
     ]
    }
   ],
   "source": [
    "# trial 5 (now trial 3): undersampling on the majority class ('neutral')\n",
    "# and oversampling on the minority classes ('positive' and 'negative')\n",
    "\n",
    "\n",
    "# undersample 'neutral' class\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "X_train_balanced, y_train_balanced = undersampler.fit_resample(\n",
    "    X_train, y_train_opt)\n",
    "\n",
    "# oversample 'positive' and 'negative' classes\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "X_train_balanced, y_train_balanced = oversampler.fit_resample(\n",
    "    X_train_balanced, y_train_balanced)\n",
    "\n",
    "# oversample twice to create equal distribution of sentiments\n",
    "X_train_balanced, y_train_balanced = oversampler.fit_resample(\n",
    "    X_train_balanced, y_train_balanced)\n",
    "\n",
    "# uncomment code below to look at the resampled sentiment distribution\n",
    "# unique_values, counts = np.unique(y_train_balanced, return_counts=True)\n",
    "# for value, count in zip(unique_values, counts):\n",
    "#     print(f\"{value}: {count}\")\n",
    "# it's now 1:1:1, balanced!\n",
    "\n",
    "# one-hot code resampled y\n",
    "y_train_balanced = to_categorical(y_train_balanced, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_5 = Sequential()\n",
    "model_5.add(Embedding(input_dim=vocab_size, output_dim=32, \n",
    "                      input_length=max_len))\n",
    "model_5.add(LSTM(units=32)) \n",
    "\n",
    "model_5.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model_5.compile(loss='categorical_crossentropy', optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_5.fit(X_train_balanced, y_train_balanced, validation_data=(X_val, y_val), \n",
    "          epochs=30, batch_size=128, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model_5.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the bank announcement data\n",
    "loss, accuracy = model_5.evaluate(paragraph_reviewed_X, paragraph_reviewed_y)\n",
    "\n",
    "print(f\"Announcement data test Loss: {loss:.4f}\")\n",
    "print(f\"Announcement data test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# result: performance slightly worse than trial 1 (discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 17ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  8  9]\n",
      " [26 10 16]\n",
      " [29 12  7]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix under trial 5 (now trial 3)\n",
    "\n",
    "predictions_5 = model_5.predict(paragraph_reviewed_X)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "predicted_labels_5 = np.argmax(predictions_5, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(np.argmax(paragraph_reviewed_y, \n",
    "                                                      axis=1), \n",
    "                                            predicted_labels_5)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 4s 135ms/step - loss: 1.0970 - accuracy: 0.3569 - val_loss: 1.0980 - val_accuracy: 0.3544\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 1.0871 - accuracy: 0.6049 - val_loss: 1.0834 - val_accuracy: 0.5714\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.0687 - accuracy: 0.6761 - val_loss: 1.0451 - val_accuracy: 0.6600\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 1.0320 - accuracy: 0.5498 - val_loss: 0.9587 - val_accuracy: 0.6817\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.9671 - accuracy: 0.6779 - val_loss: 0.8729 - val_accuracy: 0.6582\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.8729 - accuracy: 0.6779 - val_loss: 0.8938 - val_accuracy: 0.5931\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.7666 - accuracy: 0.7155 - val_loss: 0.8659 - val_accuracy: 0.6022\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.6546 - accuracy: 0.7625 - val_loss: 0.8292 - val_accuracy: 0.6311\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.5538 - accuracy: 0.8100 - val_loss: 0.7314 - val_accuracy: 0.6637\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.4729 - accuracy: 0.8505 - val_loss: 0.8608 - val_accuracy: 0.6311\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.3992 - accuracy: 0.8853 - val_loss: 0.6909 - val_accuracy: 0.6980\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.3554 - accuracy: 0.8998 - val_loss: 0.9268 - val_accuracy: 0.6004\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.3147 - accuracy: 0.9125 - val_loss: 0.7019 - val_accuracy: 0.7071\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.2606 - accuracy: 0.9357 - val_loss: 0.7308 - val_accuracy: 0.7197\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.2124 - accuracy: 0.9490 - val_loss: 0.8084 - val_accuracy: 0.7089\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.1738 - accuracy: 0.9658 - val_loss: 0.8808 - val_accuracy: 0.7052\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.6585 - accuracy: 0.7438\n",
      "Test Loss: 0.6585\n",
      "Test Accuracy: 0.7438\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3399 - accuracy: 0.4020\n",
      "Announcement data test Loss: 1.3399\n",
      "Announcement data test Accuracy: 0.4020\n"
     ]
    }
   ],
   "source": [
    "# trial 6 (now trial 4): trial 5 (now trial 3) but with a mix of both dataset 1 & 2A\n",
    "# this means we randomly select 20% paragraphs in dataset 2A\n",
    "# to put in the training set\n",
    "\n",
    "\n",
    "# data preprocessing\n",
    "\n",
    "# split the 20% paragraphs out\n",
    "paragraph_reviewed_train, paragraph_reviewed_test = train_test_split(\n",
    "    paragraph_reviewed, test_size=0.8, random_state=42)\n",
    "\n",
    "paragraph_reviewed_train_X = paragraph_reviewed_train['text_content'].values\n",
    "paragraph_reviewed_train_y = paragraph_reviewed_train['sentiment'].values\n",
    "\n",
    "paragraph_reviewed_test_X = paragraph_reviewed_test['text_content'].values\n",
    "paragraph_reviewed_test_y = paragraph_reviewed_test['sentiment'].values\n",
    "\n",
    "# tokenize and pad X\n",
    "paragraph_reviewed_train_X = tokenizer.texts_to_sequences(\n",
    "    paragraph_reviewed_train_X)\n",
    "\n",
    "paragraph_reviewed_test_X = tokenizer.texts_to_sequences(\n",
    "    paragraph_reviewed_test_X)\n",
    "\n",
    "paragraph_reviewed_train_X = pad_sequences(paragraph_reviewed_train_X, \n",
    "                                           maxlen=max_len)\n",
    "paragraph_reviewed_test_X = pad_sequences(paragraph_reviewed_test_X, \n",
    "                                          maxlen=max_len)\n",
    "\n",
    "# convert to numeric category & one-hot code y\n",
    "paragraph_reviewed_train_y = le.fit_transform(paragraph_reviewed_train_y)\n",
    "paragraph_reviewed_train_y = to_categorical(\n",
    "    paragraph_reviewed_train_y, num_classes)\n",
    "\n",
    "paragraph_reviewed_test_y = le.fit_transform(paragraph_reviewed_test_y)\n",
    "paragraph_reviewed_test_y = to_categorical(\n",
    "    paragraph_reviewed_test_y, num_classes)\n",
    "\n",
    "# convert to np array for concatenation\n",
    "paragraph_reviewed_train_X = np.array(paragraph_reviewed_train_X)\n",
    "paragraph_reviewed_test_X = np.array(paragraph_reviewed_test_X)\n",
    "\n",
    "# create new training and test sets containing mixed data\n",
    "mix_training_X = np.concatenate((paragraph_reviewed_train_X, X_train_balanced))\n",
    "mix_training_y = np.concatenate((paragraph_reviewed_train_y, y_train_balanced))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# modelling\n",
    "\n",
    "model_6 = Sequential()\n",
    "model_6.add(Embedding(input_dim=vocab_size, output_dim=32, \n",
    "                      input_length=max_len))\n",
    "model_6.add(LSTM(units=32)) \n",
    "\n",
    "model_6.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model_6.compile(loss='categorical_crossentropy', optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_6.fit(mix_training_X, mix_training_y, validation_data=(X_val, y_val), \n",
    "          epochs=30, batch_size=128, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model_6.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the split out test set from bank announcement data\n",
    "loss, accuracy = model_6.evaluate(paragraph_reviewed_test_X, \n",
    "                                  paragraph_reviewed_test_y)\n",
    "\n",
    "print(f\"Announcement data test Loss: {loss:.4f}\")\n",
    "print(f\"Announcement data test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 21ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6  6 15]\n",
      " [12 25 15]\n",
      " [10 10 28]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix under trial 6 (now trial 4)\n",
    "\n",
    "predictions_6 = model_6.predict(paragraph_reviewed_X)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "predicted_labels_6 = np.argmax(predictions_6, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(np.argmax(paragraph_reviewed_y, \n",
    "                                                      axis=1), \n",
    "                                            predicted_labels_6)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 20ms/step\n",
      "22/22 [==============================] - 0s 17ms/step\n",
      "22/22 [==============================] - 0s 17ms/step\n",
      "22/22 [==============================] - 0s 18ms/step\n",
      "Test Accuracy (phrasebank data): 0.7656\n",
      "Test Accuracy (announcement data): 0.3386\n"
     ]
    }
   ],
   "source": [
    "# trial 7(now trial 5): ensemble model 3 (now trial 1), 4 (now trial 2), 5 (now trial 3), 6 (now trial 4)\n",
    "\n",
    "\n",
    "# ensemble method: majority vote across predictions make by diff. models\n",
    "\n",
    "def major_vote(arr):\n",
    "    # i.e. arr = [pred_1, pred_3, pred_4]\n",
    "    # loop thorugh all 691 observations\n",
    "    # for each observarion:\n",
    "    # find the most common label given by the pred in arr\n",
    "    # return all the most common labels\n",
    "    result = []\n",
    "    for index in range(len(arr[0])):\n",
    "        column = [row[index] for row in arr]\n",
    "        counts = Counter(column)\n",
    "        most_common = counts.most_common(1)[0][0]\n",
    "        result.append(most_common)\n",
    "    return result\n",
    "\n",
    "\n",
    "# ensemble model on phrasebank data\n",
    "pred_3 = model_3.predict(X_test)\n",
    "pred_4 = model_4.predict(X_test)\n",
    "pred_5 = model_5.predict(X_test)\n",
    "pred_6 = model_6.predict(X_test)\n",
    "\n",
    "# Convert predictions to one-hot encoded format\n",
    "pred_3 = np.argmax(pred_3, axis=1)\n",
    "pred_4 = np.argmax(pred_4, axis=1)\n",
    "pred_5 = np.argmax(pred_5, axis=1)\n",
    "pred_6 = np.argmax(pred_6, axis=1)\n",
    "\n",
    "# Combine the predictions using a voting approach\n",
    "pred_3456 = np.array(major_vote([pred_6, pred_3, pred_4, pred_5]))\n",
    "# one-hot code pred to match the format of y_test\n",
    "pred_3456 = to_categorical(pred_3456, num_classes)\n",
    "\n",
    "pred_accuracy = accuracy_score(pred_3456, y_test)\n",
    "\n",
    "print(f\"Test Accuracy (phrasebank data): {pred_accuracy:.4f}\")\n",
    "\n",
    "# result: test accuracy for phrasebank data is similar to single models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ensemble model on bank announcement data\n",
    "pred_3456 = np.array(major_vote([predicted_labels_3, \n",
    "                                 predicted_labels_4, \n",
    "                                 predicted_labels_5,\n",
    "                                 predicted_labels_6]))\n",
    "pred_3456 = to_categorical(pred_3456, num_classes)\n",
    "\n",
    "pred_accuracy = accuracy_score(pred_3456, paragraph_reviewed_y)\n",
    "print(f\"Test Accuracy (announcement data): {pred_accuracy:.4f}\")\n",
    "\n",
    "# result: no improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the article predictions are correct with word2vec_model\n",
    "# # replace word2vec_model with your model name\n",
    "\n",
    "# # predict the sentiment\n",
    "# predictions_word2vec = word2vec_model.predict(paragraph_reviewed_X)\n",
    "\n",
    "# # Convert the probabilities to class labels\n",
    "# predictions_word2vec = np.argmax(predictions_word2vec, axis=1)\n",
    "\n",
    "# # add predicted labels to dataset 2, i.e. 'paragraph_reviewed'\n",
    "# paragraph_reviewed['predicted_sentiment'] = predictions_word2vec\n",
    "\n",
    "# # look at what dataset 2A (paragraph_reviewed) looks like\n",
    "# # print(paragraph_reviewed.head())\n",
    "\n",
    "# # aggregate sentiment labels via majority voting\n",
    "# # group by ArticleID and calculate the mode (most common prediction)\n",
    "# sentiment_by_article = paragraph_reviewed.groupby('aID'\n",
    "#         )['predicted_sentiment'].apply(lambda x: x.mode()[0]).reset_index()\n",
    "\n",
    "# # look at the new dataset containing the article id's and its corresponding\n",
    "# # sentiment predictions\n",
    "# # print(sentiment_by_article.head())\n",
    "\n",
    "# # note:\n",
    "# # the encoding mapping of sentiment labels is as below\n",
    "# # negative: 0\n",
    "# # neutral: 1\n",
    "# # positive: 2\n",
    "\n",
    "# # also encode true sentiment labels in the above format\n",
    "# true_sentiments = le.fit_transform(article_reviewed['sentiment_overall'])\n",
    "\n",
    "# # test if the sentiments by article is correctly predicted\n",
    "# print(\"sentiment accuracy by article:\", accuracy_score(true_sentiments, \n",
    "#                                 sentiment_by_article['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Dataset 2 (web scrapped)\n",
    "\n",
    "paragraph = pd.read_csv('bank_publications_in_paragraph.csv')\n",
    "article = pd.read_csv('bank_publications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of paragraphs in total: 14222\n",
      "number of articles in paragraph file: 1118\n",
      "number of articles in article file: 1289\n",
      "the percentage of meaninglessly short paragraphs 0.16\n",
      "number of paragraphs in total after filtering: 11903\n",
      "number of articles in paragraph file after filtering: 859\n",
      "number of articles in article file after filtering: 859\n",
      "    ArticleID                                          Paragraph\n",
      "6          14  Good morning. I’m pleased to be here with Seni...\n",
      "9          14  Inflation is coming down quickly and is foreca...\n",
      "10         14  Our destination is the 2% inflation target, an...\n",
      "11         14  We are focused on these indicators, and the ev...\n",
      "13         14  Since we last updated our economic projection ...\n",
      "\n",
      "     ArticleID                                               Link  \\\n",
      "13         14  https://www.bankofcanada.ca/2023/04/opening-st...   \n",
      "14         15  https://www.bankofcanada.ca/multimedia/speech-...   \n",
      "22         23  https://www.bankofcanada.ca/multimedia/speech-...   \n",
      "40         41  https://www.bankofcanada.ca/multimedia/speech-...   \n",
      "62         63  https://www.bankofcanada.ca/multimedia/speech-...   \n",
      "\n",
      "                                                Title    Publication Date  \n",
      "13  Monetary Policy Report Press Conference Openin...      April 12, 2023  \n",
      "14  Speech: 21st National Bank Financial Services ...      March 29, 2023  \n",
      "22  Speech: Alberta School of Business, University...   February 16, 2023  \n",
      "40  Speech: Ottawa chapter of Young Canadians in F...   November 22, 2022  \n",
      "62     Speech: University of Waterloo Faculty of Arts  September 20, 2022  \n"
     ]
    }
   ],
   "source": [
    "# EDA & data cleaning for Dataset 2\n",
    "\n",
    "# drop the NAs\n",
    "paragraph = paragraph.dropna()\n",
    "article = article.dropna()\n",
    "\n",
    "# number of paragraphs\n",
    "print(\"number of paragraphs in total:\", paragraph.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "# number of articles, notice the discrepancy between article # in each data file\n",
    "# to be fixed after cleaning\n",
    "print(\"number of articles in paragraph file:\", \n",
    "      len(paragraph[\"ArticleID\"].unique()))\n",
    "\n",
    "print(\"number of articles in article file:\", article.shape[0])\n",
    "\n",
    "# the % invalid paragraphs that are meaninglessly short\n",
    "invalid_paras = paragraph[paragraph['Paragraph'].str.len() < 160]\n",
    "print(\"the percentage of meaninglessly short paragraphs\", \n",
    "       f'{len(invalid_paras) / paragraph.shape[0]:.2f}')\n",
    "\n",
    "# remove these paragraphs\n",
    "paragraph = paragraph.drop(invalid_paras.index)\n",
    "print(\"number of paragraphs in total after filtering:\", paragraph.shape[0])\n",
    "\n",
    "# remove the articles that are gone as the paragraphs gets deleted\n",
    "# as well as the articles that didn't exist at the beginning (discrepancy)\n",
    "article = article[article[\"ArticleID\"].isin(\n",
    "    paragraph[\"ArticleID\"].unique())]\n",
    "\n",
    "# check if the number of articles match\n",
    "print(\"number of articles in paragraph file after filtering:\", \n",
    "      len(paragraph[\"ArticleID\"].unique()))\n",
    "print(\"number of articles in article file after filtering:\", \n",
    "      len(article[\"ArticleID\"].unique()))\n",
    "# they do\n",
    "\n",
    "\n",
    "# cleaned datasets\n",
    "print(paragraph.head())\n",
    "print(\"\\n\", article.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the paragraphs\n",
    "\n",
    "# same procedure as preprocessing Dataset 1\n",
    "\n",
    "paragraph['Paragraph'] = paragraph['Paragraph'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_X = paragraph['Paragraph'].values\n",
    "\n",
    "# tokenize and pad the sequences\n",
    "paragraph_X = tokenizer.texts_to_sequences(paragraph_X)\n",
    "paragraph_X = pad_sequences(paragraph_X, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/372 [..............................] - ETA: 15s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 7s 19ms/step\n",
      "    ArticleID                                          Paragraph  \\\n",
      "6          14  good morning ’ pleased senior deputy governor ...   \n",
      "9          14  inflation coming quickly forecast around 3 sum...   \n",
      "10         14  destination 2 inflation target several thing s...   \n",
      "11         14  focused indicator evolution core inflation ens...   \n",
      "13         14  since last updated economic projection january...   \n",
      "\n",
      "    predicted_sentiment  \n",
      "6                     2  \n",
      "9                     2  \n",
      "10                    2  \n",
      "11                    0  \n",
      "13                    2  \n",
      "   ArticleID  predicted_sentiment\n",
      "0         14                    2\n",
      "1         15                    1\n",
      "2         23                    1\n",
      "3         41                    1\n",
      "4         63                    1\n"
     ]
    }
   ],
   "source": [
    "# predict the sentiment of all web scrapped announcements\n",
    "\n",
    "predictions_word2vec = model_6.predict(paragraph_X)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "predictions_word2vec = np.argmax(predictions_word2vec, axis=1)\n",
    "\n",
    "# add predicted labels to dataset 2, i.e. 'paragraph'\n",
    "paragraph['predicted_sentiment'] = predictions_word2vec\n",
    "\n",
    "# look at what dataset 2 (paragraph) looks like\n",
    "print(paragraph.head())\n",
    "\n",
    "# aggregate sentiment labels via majority voting\n",
    "# group by ArticleID and calculate the mode (most common prediction)\n",
    "sentiment_by_article = paragraph.groupby('ArticleID'\n",
    "        )['predicted_sentiment'].apply(lambda x: x.mode()[0]).reset_index()\n",
    "\n",
    "# look at the new dataset containing the article id's and its corresponding\n",
    "# sentiment predictions\n",
    "print(sentiment_by_article.head())\n",
    "# note:\n",
    "# the encoding mapping of sentiment labels is as below\n",
    "# negative: 0\n",
    "# neutral: 1\n",
    "# positive: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-01-11 00:00:00 2023-06-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# step 3. observe daily stock index change & BoC sentiments\n",
    "\n",
    "\n",
    "\n",
    "# find the time range to extract from dataset 3\n",
    "\n",
    "\n",
    "# Convert the date column to datetime format\n",
    "article['Publication Date'] = pd.to_datetime(\n",
    "    article['Publication Date'], format='%B %d, %Y')\n",
    "\n",
    "# Find the earliest and latest dates\n",
    "earliest_date = article['Publication Date'].min()\n",
    "latest_date = article['Publication Date'].max()\n",
    "\n",
    "print(earliest_date, latest_date)\n",
    "# printed 2010-01-11 and 2023-06-07\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date          Open          High           Low         Close  \\\n",
      "3372 2023-06-12  19862.599609  19933.599609  19805.900391  19921.300781   \n",
      "3373 2023-06-13  19998.300781  20099.199219  19975.900391  19990.400391   \n",
      "3374 2023-06-14  20027.800781  20098.500000  19930.300781  20015.099609   \n",
      "3375 2023-06-15  19986.099609  20057.400391  19952.199219  20027.400391   \n",
      "3376 2023-06-16  20057.300781  20112.400391  19973.199219  19975.400391   \n",
      "\n",
      "         Adj Close     Volume  \n",
      "3372  19921.300781  212148400  \n",
      "3373  19990.400391  205098400  \n",
      "3374  20015.099609  212250000  \n",
      "3375  20027.400391  199331900  \n",
      "3376  19975.400391  499628700  \n"
     ]
    }
   ],
   "source": [
    "# import Dataset 3\n",
    "stock_price = pd.read_csv('tsx_index_prices.csv')\n",
    "\n",
    "# Convert the \"Date\" column in stock data to datetime format\n",
    "stock_price['Date'] = pd.to_datetime(stock_price['Date'])\n",
    "\n",
    "# descriptive stats\n",
    "print(stock_price.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ArticleID       Date         Close  prev_stock_avg  after_stock_avg\n",
      "0         14 2023-04-12  20454.300781    20298.133464     20595.466797\n",
      "1        883 2023-04-12  20454.300781    20298.133464     20595.466797\n",
      "2         15 2023-03-29  19837.699219    19594.566406     20106.400391\n",
      "3         23 2023-02-16  20606.400391    20709.133464     20320.366536\n",
      "4         41 2022-11-22  20220.000000    19947.533203     20336.733724\n"
     ]
    }
   ],
   "source": [
    "# Merge the dataframes based on the common date and publish date columns\n",
    "merged_df = pd.merge(article, stock_price, left_on=article[\n",
    "    'Publication Date'].dt.strftime('%Y-%m-%d'),\n",
    "                     right_on=stock_price['Date'].dt.strftime('%Y-%m-%d'))\n",
    "\n",
    "# Calculate the average stock prices 3 days before and\n",
    "# 3 days after the publish date\n",
    "# Initialize empty lists to store the average stock prices\n",
    "prev_stock_avg_list = []\n",
    "after_stock_avg_list = []\n",
    "\n",
    "# Iterate over the rows of announcement data\n",
    "# for each announcement, find the avg\n",
    "# of the closing price 3 days before and 3 days after\n",
    "# its publication date\n",
    "# store each avg in a list\n",
    "for _, row in merged_df.iterrows():\n",
    "    publish_date = row['Publication Date']\n",
    "\n",
    "    # note to Jasmeet: adjust the number in tail() and head()\n",
    "    # to control how many days to average on :)\n",
    "\n",
    "    # i.e. (3) means take avg price of 3 days prev. and after the publish date\n",
    "    prev_dates = stock_price[stock_price['Date'] < \n",
    "                             publish_date]['Date'].tail(3)\n",
    "    after_dates = stock_price[stock_price['Date'] > \n",
    "                              publish_date]['Date'].head(3)\n",
    "    prev_stock_avg = stock_price[stock_price['Date'].isin(\n",
    "        prev_dates)]['Close'].mean()\n",
    "    after_stock_avg = stock_price[stock_price['Date'].isin(\n",
    "        after_dates)]['Close'].mean()\n",
    "    prev_stock_avg_list.append(prev_stock_avg)\n",
    "    after_stock_avg_list.append(after_stock_avg)\n",
    "\n",
    "# Add the average stock prices as columns in merged_df\n",
    "merged_df['prev_stock_avg'] = prev_stock_avg_list\n",
    "merged_df['after_stock_avg'] = after_stock_avg_list\n",
    "\n",
    "\n",
    "# keep only the relevant columns\n",
    "merged_df = merged_df[['ArticleID', 'Date', 'Close',\n",
    "                       'prev_stock_avg', 'after_stock_avg']] \n",
    "\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ArticleID       Date         Close  prev_stock_avg  after_stock_avg  \\\n",
      "0         14 2023-04-12  20454.300781    20298.133464     20595.466797   \n",
      "1        883 2023-04-12  20454.300781    20298.133464     20595.466797   \n",
      "2         15 2023-03-29  19837.699219    19594.566406     20106.400391   \n",
      "3         23 2023-02-16  20606.400391    20709.133464     20320.366536   \n",
      "4         41 2022-11-22  20220.000000    19947.533203     20336.733724   \n",
      "\n",
      "   prev_change  after_change  \n",
      "0     0.007694      0.006902  \n",
      "1     0.007694      0.006902  \n",
      "2     0.012408      0.013545  \n",
      "3    -0.004961     -0.013881  \n",
      "4     0.013659      0.005773  \n"
     ]
    }
   ],
   "source": [
    "# calculate the % change in stock prices \n",
    "# merged_df['Close'] = stock price at publication date\n",
    "merged_df['prev_change'] = (merged_df['Close'] - prev_stock_avg_list) \\\n",
    "    / prev_stock_avg_list\n",
    "merged_df['after_change'] = (after_stock_avg_list - merged_df['Close']) \\\n",
    "    / merged_df['Close']\n",
    "\n",
    "print(merged_df.head())\n",
    "\n",
    "# it seems like the % changes within 3 days prior and after are quite small.\n",
    "# I've tried 1 day & 7 days as well and got similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we look at if there is a discontinuity in relative price changes\n",
    "\n",
    "# merged_df['relative_change'] = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco480",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
